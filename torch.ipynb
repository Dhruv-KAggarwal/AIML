{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU avaviable: True\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim \n",
    "import torch.nn as nn \n",
    "\n",
    "\n",
    "print(\"GPU avaviable: {}\".format (torch.cuda.is_available()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform to a Pytorch tensors and the normalize our values between -1 and +1\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,),(0.5, ))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load our Training Data and specify what transform to use when loading \n",
    "trainset = torchvision.datasets.MNIST('mnist',\n",
    "                                      train=True,\n",
    "                                      download=True,\n",
    "                                      transform=transform)\n",
    "\n",
    "#Load our TEST data and specify what transform to use when loading \n",
    "testset = torchvision.datasets.MNIST('mnist',\n",
    "                                     train=False,\n",
    "                                     download=True,\n",
    "                                     transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,  13,  25, 100, 122,   7,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  33,\n",
      "         151, 208, 252, 252, 252, 146,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  40, 152, 244,\n",
      "         252, 253, 224, 211, 252, 232,  40,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  15, 152, 239, 252, 252,\n",
      "         252, 216,  31,  37, 252, 252,  60,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  96, 252, 252, 252, 252,\n",
      "         217,  29,   0,  37, 252, 252,  60,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0, 181, 252, 252, 220, 167,\n",
      "          30,   0,   0,  77, 252, 252,  60,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  26, 128,  58,  22,   0,\n",
      "           0,   0,   0, 100, 252, 252,  60,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0, 157, 252, 252,  60,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110,\n",
      "         121, 122, 121, 202, 252, 194,   3,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,  53, 179, 253,\n",
      "         253, 255, 253, 253, 228,  35,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   5,  54, 227, 252, 243, 228,\n",
      "         170, 242, 252, 252, 231, 117,   6,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   6,  78, 252, 252, 125,  59,   0,\n",
      "          18, 208, 252, 252, 252, 252,  87,   7,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   5, 135, 252, 252, 180,  16,   0,  21,\n",
      "         203, 253, 247, 129, 173, 252, 252, 184,  66,  49,  49,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   3, 136, 252, 241, 106,  17,   0,  53, 200,\n",
      "         252, 216,  65,   0,  14,  72, 163, 241, 252, 252, 223,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 105, 252, 242,  88,  18,  73, 170, 244, 252,\n",
      "         126,  29,   0,   0,   0,   0,   0,  89, 180, 180,  37,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 231, 252, 245, 205, 216, 252, 252, 252, 124,\n",
      "           3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 207, 252, 252, 252, 252, 178, 116,  36,   4,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,  13,  93, 143, 121,  23,   6,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
      "       dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(trainset.data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Define our imshow function\n",
    "\n",
    "def imgshow(title=\"\", image=None, size= 5):\n",
    "    w, h =image.shape[0], image.shape[1]\n",
    "    aspect_ratio = w/h\n",
    "    plt.figure(figsize=(size*aspect_ratio, size))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#convert image to a numpy array\n",
    "image = trainset.data[5].numpy()\n",
    "imgshow(\"MNIST Sample\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=128,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=0)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         batch_size=128,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "import numpy\n",
    "images, labels = dataiter.__next__()\n",
    "print(images.shape)\n",
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 *12*12, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x =F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1,64*12*12)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x \n",
    "    \n",
    "net = Net()\n",
    "net.to(device=\"cuda\")\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch: 1....\n",
      "Epoch: 1, Mini-Batch Completed: 50, Loss: 0.373, Test Accuracy: 89.800\n",
      "Epoch: 1, Mini-Batch Completed: 100, Loss: 0.353, Test Accuracy: 89.970\n",
      "Epoch: 1, Mini-Batch Completed: 150, Loss: 0.335, Test Accuracy: 89.600\n",
      "Epoch: 1, Mini-Batch Completed: 200, Loss: 0.356, Test Accuracy: 90.750\n",
      "Epoch: 1, Mini-Batch Completed: 250, Loss: 0.346, Test Accuracy: 90.780\n",
      "Epoch: 1, Mini-Batch Completed: 300, Loss: 0.330, Test Accuracy: 90.800\n",
      "Epoch: 1, Mini-Batch Completed: 350, Loss: 0.316, Test Accuracy: 91.260\n",
      "Epoch: 1, Mini-Batch Completed: 400, Loss: 0.287, Test Accuracy: 91.020\n",
      "Epoch: 1, Mini-Batch Completed: 450, Loss: 0.322, Test Accuracy: 91.110\n",
      "Finished Training\n",
      "Starting epoch: 2....\n",
      "Epoch: 2, Mini-Batch Completed: 50, Loss: 0.287, Test Accuracy: 92.500\n",
      "Epoch: 2, Mini-Batch Completed: 100, Loss: 0.286, Test Accuracy: 92.580\n",
      "Epoch: 2, Mini-Batch Completed: 150, Loss: 0.271, Test Accuracy: 92.350\n",
      "Epoch: 2, Mini-Batch Completed: 200, Loss: 0.264, Test Accuracy: 92.960\n",
      "Epoch: 2, Mini-Batch Completed: 250, Loss: 0.276, Test Accuracy: 93.110\n",
      "Epoch: 2, Mini-Batch Completed: 300, Loss: 0.248, Test Accuracy: 93.190\n",
      "Epoch: 2, Mini-Batch Completed: 350, Loss: 0.235, Test Accuracy: 93.580\n",
      "Epoch: 2, Mini-Batch Completed: 400, Loss: 0.225, Test Accuracy: 94.030\n",
      "Epoch: 2, Mini-Batch Completed: 450, Loss: 0.244, Test Accuracy: 94.290\n",
      "Finished Training\n",
      "Starting epoch: 3....\n",
      "Epoch: 3, Mini-Batch Completed: 50, Loss: 0.218, Test Accuracy: 94.110\n",
      "Epoch: 3, Mini-Batch Completed: 100, Loss: 0.218, Test Accuracy: 94.210\n",
      "Epoch: 3, Mini-Batch Completed: 150, Loss: 0.212, Test Accuracy: 94.210\n",
      "Epoch: 3, Mini-Batch Completed: 200, Loss: 0.210, Test Accuracy: 94.440\n",
      "Epoch: 3, Mini-Batch Completed: 250, Loss: 0.193, Test Accuracy: 94.660\n",
      "Epoch: 3, Mini-Batch Completed: 300, Loss: 0.196, Test Accuracy: 94.280\n",
      "Epoch: 3, Mini-Batch Completed: 350, Loss: 0.194, Test Accuracy: 94.740\n",
      "Epoch: 3, Mini-Batch Completed: 400, Loss: 0.197, Test Accuracy: 94.650\n",
      "Epoch: 3, Mini-Batch Completed: 450, Loss: 0.180, Test Accuracy: 95.410\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define your training loop\n",
    "epochs = 3  # Correct the variable name\n",
    "\n",
    "epoch_log = []\n",
    "loss_log = []\n",
    "accuracy_log = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Starting epoch: {epoch + 1}....')\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device=\"cuda\")\n",
    "        labels = labels.to(device=\"cuda\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for data in testloader:\n",
    "                    images, labels = data\n",
    "                    images = images.to(device=\"cuda\")\n",
    "                    labels = labels.to(device=\"cuda\")\n",
    "\n",
    "                    outputs = net(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "            epoch_num = epoch + 1\n",
    "            actual_loss = running_loss / 50\n",
    "            print(f'Epoch: {epoch_num}, Mini-Batch Completed: {i + 1}, Loss: {actual_loss:.3f}, Test Accuracy: {accuracy:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "            epoch_log.append(epoch_num)\n",
    "            loss_log.append(actual_loss)\n",
    "            accuracy_log.append(accuracy)\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "# Note: The indentation of the final print statement is fixed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"mnist_cnn_net.pth\"\n",
    "torch.save(net.state_dict(), path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.to(device=\"cuda\")\n",
    "\n",
    "net.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m outputs \u001b[38;5;241m=\u001b[39m net(images)\n\u001b[0;32m      7\u001b[0m predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs , \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%ls\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[23], line 9\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m outputs \u001b[38;5;241m=\u001b[39m net(images)\n\u001b[0;32m      7\u001b[0m predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs , \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%ls\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[43mpredicted\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m128\u001b[39m)))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "test_iter = iter(testloader)\n",
    "images, labels = test_iter.__next__()\n",
    "images = images.to(device=\"cuda\")\n",
    "labels = labels.to(device= \"cuda\")\n",
    "outputs = net(images)\n",
    "\n",
    "predicted = torch.max(outputs , 1)\n",
    "\n",
    "print('Predicted: ', ''.join('%ls' % predicted[j].cpu().numpy() for j in range(128)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
